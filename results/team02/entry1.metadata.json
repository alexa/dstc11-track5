{
  "subtask1": {
    "ensemble": "No, only a single model was used for the turn detection",
    "pretrained": "microsoft/deberta-v3-base",
    "external_api": "NIL",
    "desc": "We used the provided baseline"
  },
  "subtask2": {
    "ensemble": "No, only a single model was used for the knowledge selection",
    "pretrained": "microsoft/deberta-v3-base",
    "external_api": "NIL",
    "desc": "We used the provided baseline"
  },
  "subtask3": {
    "ensemble": "No, only a single model was used for the response generation",
    "pretrained": "LLaMA 7B LoRA",
    "external_api": "NIL",
    "desc": "[2nd highest priority for human eval]. Finetuned LLaMA 7B using PEFT and LoRA on Stanford instruction data, then finetuned on track 5 data with prompting."
  }
}